{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd05e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f05670",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_artifacts = Path.cwd().resolve().parents[1] / 'CausalI2I_artifacts'\n",
    "data_path_goodreads = base_artifacts / 'Datasets' / 'Processed' / 'goodreads'\n",
    "data_path_sequels = base_artifacts / 'Datasets' / 'Sequels'\n",
    "\n",
    "train = pd.read_csv(data_path_goodreads / 'train.csv')\n",
    "test = pd.read_csv(data_path_goodreads / 'test.csv')\n",
    "with open(data_path_goodreads / 'item_dict.pkl', 'rb') as f:\n",
    "    item_dict = pickle.load(f)\n",
    "\n",
    "n_users = len(train['user_id'].unique())\n",
    "n_items = len(item_dict)\n",
    "\n",
    "full_data = pd.concat([train, test], ignore_index=True)\n",
    "title2id = {v: k for k, v in item_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f288d",
   "metadata": {},
   "source": [
    "### Find titles that:\n",
    " * Belong to a series, and\n",
    " * From this series there is more than one book in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7f44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path_sequels / 'name2series.pkl', 'rb') as f:\n",
    "    name2series = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0dae42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items with precomputed series: 3780 out of 6384\n"
     ]
    }
   ],
   "source": [
    "all_titles = list(item_dict.values())\n",
    "ser_titles = [title for title in all_titles if title in name2series]\n",
    "print(f'Number of items with precomputed series: {len(ser_titles)} out of {n_items}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d997ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "serNames = [name2series[title]['series'] for title in ser_titles]\n",
    "ser = pd.Series(serNames).value_counts()\n",
    "good_series = ser[ser > 1].index.tolist()\n",
    "good_titles = [title for title in ser_titles if name2series[title]['series'] in good_series]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8ab49",
   "metadata": {},
   "source": [
    "### Out of the `good_titles` find those that are popular in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d586a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2series = {title2id[title]: name2series[title]['series'] for title in good_titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc09563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_data[full_data['interaction'] == 1].copy()\n",
    "df['series'] = df['item_id'].apply(\n",
    "    lambda x: id2series.get(x, np.nan)\n",
    ")\n",
    "df = df.dropna(subset=['series'])\n",
    "\n",
    "series_summaries = (\n",
    "    df\n",
    "    .groupby('series')\n",
    "    .agg({\n",
    "        'interaction': 'size', \n",
    "        'item_id': 'nunique'\n",
    "    })\n",
    "    .sort_values(by='interaction', ascending=False)\n",
    ")\n",
    "series_summaries['cumsum'] = series_summaries['item_id'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e876a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chosen items: 1,274\n",
      "Number of chosen series: 248\n",
      "Number of labeled pairs: 7,386\n"
     ]
    }
   ],
   "source": [
    "candidates = series_summaries[series_summaries['cumsum'] < n_items * 0.2]\n",
    "chosen_series = candidates.index.tolist()\n",
    "chosen_ids = [item_id for item_id, series in id2series.items() if series in chosen_series]\n",
    "\n",
    "print(f\"Number of chosen items: {len(chosen_ids):,}\")\n",
    "print(f\"Number of chosen series: {len(chosen_series):,}\")\n",
    "print(f\"Number of labeled pairs: {candidates['item_id'].apply(lambda x: x * (x-1)).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6832f28",
   "metadata": {},
   "source": [
    "### Set new train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79cb144",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = full_data['user_id'].unique().tolist()\n",
    "unique_items = full_data['item_id'].unique().tolist()\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "test_users = rng.choice(unique_users, size=int(0.5 * len(unique_users)), replace=False).tolist()\n",
    "train_users = [u for u in unique_users if u not in test_users]\n",
    "test_items = chosen_ids\n",
    "train_items = [i for i in unique_items if i not in test_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51dc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = full_data[(full_data['user_id'].isin(train_users)) | (full_data['item_id'].isin(train_items))].copy()\n",
    "new_test = full_data[(full_data['user_id'].isin(test_users)) & (full_data['item_id'].isin(test_items))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a4707fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2info = {item_id: {\n",
    "    'title': item_dict[item_id],\n",
    "    'series': name2series[item_dict[item_id]]['series'],\n",
    "    'number': name2series[item_dict[item_id]]['number']} \n",
    "    for item_id in chosen_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "216f3320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files to disk...\n",
      "\n",
      "Files saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# 6) Save to disk\n",
    "print(\"Saving files to disk...\\n\")\n",
    "new_train.to_csv(data_path_sequels / 'train.csv', index=False)\n",
    "new_test.to_csv(data_path_sequels / 'test.csv', index=False)\n",
    "\n",
    "with open(data_path_sequels / 'id2info.pkl', 'wb') as f:\n",
    "    pickle.dump(id2info, f)\n",
    "\n",
    "print('Files saved to disk.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
