{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c132ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().resolve().parents[0] / '2_Propensities'))\n",
    "\n",
    "import MF_class as MF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2252314",
   "metadata": {},
   "source": [
    "# 1 Loading Dataset and Propensities Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318d80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_artifacts = Path.cwd().resolve().parents[1] / 'CausalI2I_artifacts'\n",
    "data_path = base_artifacts / 'Datasets' / 'Sequels'\n",
    "\n",
    "train = pd.read_csv(data_path / 'train.csv')\n",
    "test = pd.read_csv(data_path / 'test.csv')\n",
    "with open(data_path / 'id2info.pkl', 'rb') as f:\n",
    "    id2info = pickle.load(f)\n",
    "\n",
    "n_users = len(train['user_id'].unique())\n",
    "n_items = len(train['item_id'].unique())\n",
    "\n",
    "full_data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d0b171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model summary:\n",
      "Model:                      MatrixFactorizationTorch\n",
      "Number of users:            7801\n",
      "Number of items:            6384\n",
      "Number of factors:          25\n",
      "Learning rate:              0.0005\n",
      "Weight decay:               1e-07\n",
      "Positive weight:            1\n",
      "Batch size:                 32768\n",
      "Number of epochs:           40\n",
      "Device:                     cuda:0\n",
      "Use AMP:                    True\n",
      "Timestamp:                  2026-01-23 15:04:37\n"
     ]
    }
   ],
   "source": [
    "model = MF.MatrixFactorizationTorch(n_users, n_items, n_factors=25)\n",
    "model.load(path=base_artifacts / 'Propensity_Models' / 'MF25_sequels.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1c3b7",
   "metadata": {},
   "source": [
    "# 2 Build Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ddcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'title_A': [], 'title_B': [], 'causal_link': []}\n",
    "chosen_ids = []\n",
    "for item1 in id2info:\n",
    "    for item2 in id2info:\n",
    "        if item1 == item2:\n",
    "            continue\n",
    "        if id2info[item1]['series'] != id2info[item2]['series']:\n",
    "            continue\n",
    "        num1 = id2info[item1]['number']\n",
    "        num2 = id2info[item2]['number']\n",
    "        if num1 == num2:\n",
    "            continue\n",
    "        if num1 < num2:\n",
    "            link = 1\n",
    "        else:\n",
    "            link = 0\n",
    "        results['title_A'].append(id2info[item1]['title'])\n",
    "        results['title_B'].append(id2info[item2]['title'])\n",
    "        results['causal_link'].append(link)\n",
    "        chosen_ids.append((item1, item2))\n",
    "\n",
    "oracle = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fcbc49",
   "metadata": {},
   "source": [
    "# 3 Defining Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8891d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_real = full_data.pivot(index='user_id', columns='item_id', values='interaction').fillna(0)\n",
    "itemid_to_colidx_pivot_real = {item_id: col_idx for col_idx, item_id in enumerate(pivot_real.columns)}\n",
    "pivot_real_np = pivot_real.values\n",
    "\n",
    "Q_normalized = (model.Q / torch.norm(model.Q, dim=1, keepdim=True)).cpu().detach().numpy()\n",
    "\n",
    "def cosimilarity(idx1, idx2):\n",
    "    \"\"\"Calculate cosine similarity between two items.\"\"\"\n",
    "    return np.dot(Q_normalized[idx1], Q_normalized[idx2])\n",
    "\n",
    "def correlation(idx1, idx2):\n",
    "    \"\"\"Calculate correlation between two items.\"\"\"\n",
    "    colidx1 = itemid_to_colidx_pivot_real[idx1]\n",
    "    colidx2 = itemid_to_colidx_pivot_real[idx2]\n",
    "    T = pivot_real_np[:, colidx1]\n",
    "    Y = pivot_real_np[:, colidx2]\n",
    "    if T.std() == 0 or Y.std() == 0:\n",
    "        return 0\n",
    "    return np.corrcoef(T, Y)[0, 1]\n",
    "\n",
    "def diff_of_conditionals(idx1, idx2):\n",
    "    \"\"\"Calculate difference of conditionals P(Y|T) - P(Y|~T) between two items.\"\"\"\n",
    "    colidx1 = itemid_to_colidx_pivot_real[idx1]\n",
    "    colidx2 = itemid_to_colidx_pivot_real[idx2]\n",
    "    T = pivot_real_np[:, colidx1]\n",
    "    Y = pivot_real_np[:, colidx2]\n",
    "    p_T = np.clip(np.mean(T), 1e-6, 1-1e-6)\n",
    "    p_Y = np.mean(Y)\n",
    "    p_TY = np.mean(T * Y)\n",
    "    return p_TY / p_T - (p_Y - p_TY) / (1 - p_T)\n",
    "\n",
    "def jacard_index(idx1, idx2):\n",
    "    \"\"\"Calculate Jaccard index between two items.\"\"\"\n",
    "    colidx1 = itemid_to_colidx_pivot_real[idx1]\n",
    "    colidx2 = itemid_to_colidx_pivot_real[idx2]\n",
    "    T = pivot_real_np[:, colidx1]\n",
    "    Y = pivot_real_np[:, colidx2]\n",
    "    intersection = np.sum((T > 0) & (Y > 0))\n",
    "    union = np.sum((T > 0) | (Y > 0))\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ff94b",
   "metadata": {},
   "source": [
    "# 4 SASRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7310e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gouni/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /home/gouni/CausalI2I_artifacts/SASRec_Models/sasrec_goodreads.pt.\n",
      "num_items:     6384\n",
      "max_seq_len:   50\n",
      "device:        cuda\n",
      "batch_size:    2048\n",
      "lr:            0.001\n",
      "weight_decay:  0.0\n",
      "num_epochs:    20\n",
      "saved_at:      2026-01-06 09:58:04\n",
      "note:          None\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, str(Path.cwd().resolve().parents[0] / '4_SASRec'))\n",
    "import SASRec_class as sasrec\n",
    "\n",
    "parent_path = '/home/gouni/Item2ItemCausality'\n",
    "\n",
    "# Load SASRec model\n",
    "model_path = base_artifacts / 'SASRec_Models'\n",
    "with open(model_path / 'sasrec_goodreads_init_dict.pkl', 'rb') as f:\n",
    "    init_dict_loaded = pickle.load(f)\n",
    "sasrec_model = sasrec.SASRecTorch(**init_dict_loaded)\n",
    "sasrec_model.load(model_path / 'sasrec_goodreads.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5708775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequence(cause_id):\n",
    "    PAD = sasrec_model.num_items\n",
    "    L = sasrec_model.max_seq_len\n",
    "    seq = torch.full((1, L), PAD, dtype=torch.long, device=sasrec_model.device)\n",
    "    seq[0, -1] = cause_id\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a69a592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b3da34850845a8a7524e8d93685b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sasrec_model.eval()\n",
    "\n",
    "sasrec_scores = {}\n",
    "sasrec_ranks = {}\n",
    "candidates = torch.arange(0, sasrec_model.num_items, device=sasrec_model.device)\n",
    "for pair in tqdm(chosen_ids):\n",
    "    cause_id, effect_id = pair\n",
    "    seq = make_sequence(cause_id)\n",
    "    candidates_scores = sasrec_model.predict_scores(seq, candidates).detach().cpu().numpy()[0]\n",
    "    # Record Score\n",
    "    sasrec_scores[pair] = candidates_scores[effect_id]\n",
    "    # Record Rank\n",
    "    rank = np.where(candidates_scores.argsort()[::-1] == effect_id)[0][0]   # 0-based rank\n",
    "    percentile = 1 - rank / sasrec_model.num_items\n",
    "    sasrec_ranks[pair] = percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06268f3",
   "metadata": {},
   "source": [
    "# 5 Defining ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3376f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = model.predict_prob(\n",
    "        torch.tensor(test['user_id'].values, dtype=torch.long),\n",
    "        torch.tensor(test['item_id'].values, dtype=torch.long)\n",
    "    )\n",
    "test_copy = test.copy()\n",
    "if test_copy['timestamp'].dtype == 'O':\n",
    "    test_copy['timestamp'] = pd.to_datetime(test_copy['timestamp'], errors='coerce').astype(np.int64) // 10**9\n",
    "    test_copy['timestamp'] = test_copy['timestamp'].apply(lambda x: x if x > 0 else np.inf)\n",
    "\n",
    "pivot_test_timestamp = test_copy.pivot(index='user_id', columns='item_id', values='timestamp').fillna(np.inf)\n",
    "pivot_test_timestamp_np = pivot_test_timestamp.values\n",
    "itemid_to_colidx = {id: i for i, id in enumerate(pivot_test_timestamp.columns)}\n",
    "\n",
    "test_copy['probability'] = test_probs.cpu().detach().numpy()\n",
    "pivot_test_pred = test_copy.pivot(index='user_id', columns='item_id', values='probability')\n",
    "pivot_test_pred_np = pivot_test_pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fadcd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interaction_time_cols  = {\n",
    "    item: pivot_test_timestamp_np[:, colidx]\n",
    "    for item, colidx in itemid_to_colidx.items()\n",
    "}\n",
    "\n",
    "pred_cols = {\n",
    "    item: pivot_test_pred_np[:, colidx]\n",
    "    for item, colidx in itemid_to_colidx.items()\n",
    "}\n",
    "\n",
    "all_interaction_cols = {\n",
    "    item: pivot_real_np[:, colidx]\n",
    "    for item, colidx in itemid_to_colidx_pivot_real.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0a4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ATE(cause_times, effect_times, pi, clip=0, drop_inverted=True, stabilized=True):\n",
    "    \"\"\"\n",
    "    If stabilized=True  -> Hájek ratio IPW: E[Y(1)] ≈ mean(N1)/mean(D1), E[Y(0)] ≈ mean(N0)/mean(D0)\n",
    "    If stabilized=False -> Horvitz–Thompson IPW:   E[Y(1)] ≈ mean(N1),    E[Y(0)] ≈ mean(N0)\n",
    "    Returns (ATE, STD) unless return_STD=False.\n",
    "    \"\"\"\n",
    "\n",
    "    if drop_inverted:\n",
    "        users_to_keep = np.where((cause_times <= effect_times) | (cause_times == np.inf))[0]\n",
    "\n",
    "        cause_time_filtered = cause_times[users_to_keep]\n",
    "        effect_time_filtered = effect_times[users_to_keep]\n",
    "\n",
    "        T = cause_time_filtered < np.inf\n",
    "        Y = effect_time_filtered < np.inf\n",
    "        pi = pi[users_to_keep]\n",
    "\n",
    "    else:\n",
    "        T  = cause_times < np.inf\n",
    "        Y  = effect_times < np.inf\n",
    "    \n",
    "    n  = len(T)\n",
    "\n",
    "    pi = np.clip(pi, clip, 1 - clip)\n",
    "\n",
    "    # IPW pieces\n",
    "    D_1 = T / pi                # B\n",
    "    D_0 = (1 - T) / (1 - pi)    # D\n",
    "    N_1 = Y * D_1               # A\n",
    "    N_0 = Y * D_0               # C\n",
    "\n",
    "    mN_1, mN_0 = N_1.mean(), N_0.mean()\n",
    "    \n",
    "    # Point estimate\n",
    "    if stabilized:\n",
    "        # Hájek (ratio) form\n",
    "        mD_1, mD_0 = D_1.mean(), D_0.mean()\n",
    "        EY_1 = mN_1 / mD_1 if mD_1 != 0 else 0.0\n",
    "        EY_0 = mN_0 / mD_0 if mD_0 != 0 else 0.0\n",
    "    else:\n",
    "        # Horvitz–Thompson (mean) form\n",
    "        EY_1 = mN_1\n",
    "        EY_0 = mN_0\n",
    "\n",
    "    ATE = EY_1 - EY_0\n",
    "\n",
    "    # ---- Variance via explicit covariance matrix ----\n",
    "    if stabilized:\n",
    "        Z = np.column_stack([N_1, D_1, N_0, D_0])\n",
    "        S = np.cov(Z, rowvar=False, ddof=1)     # 4x4 sample covariance\n",
    "        g = np.array([\n",
    "            1.0 / mD_1 if mD_1 != 0 else 0.0,\n",
    "            -mN_1 / (mD_1 ** 2) if mD_1 != 0 else 0.0,\n",
    "            -1.0 / mD_0 if mD_0 != 0 else 0.0,\n",
    "            mN_0 / (mD_0 ** 2) if mD_0 != 0 else 0.0\n",
    "        ])\n",
    "    else:\n",
    "        Z = np.column_stack([N_1, N_0])\n",
    "        S = np.cov(Z, rowvar=False, ddof=1)     # 2x2 covariance\n",
    "        g = np.array([1.0, -1.0])\n",
    "    \n",
    "    var_hat = (g @ S @ g) / n\n",
    "    STD = float(np.sqrt(max(var_hat, 0.0)))     # numerical safety\n",
    "    \n",
    "    return {\n",
    "        \"ATE\": ATE,\n",
    "        \"STD\": STD\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4470e72",
   "metadata": {},
   "source": [
    "# 6 Generate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d73e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pair(pair):\n",
    "\n",
    "    c = pair[0]\n",
    "    e = pair[1]\n",
    "\n",
    "    ate_results = get_ATE(\n",
    "        cause_times=test_interaction_time_cols[c], \n",
    "        effect_times=test_interaction_time_cols[e], \n",
    "        pi=pred_cols[c], \n",
    "        clip=0.01, \n",
    "        drop_inverted=True, \n",
    "        stabilized=True)\n",
    "    \n",
    "    ablt_results = get_ATE(\n",
    "        cause_times=test_interaction_time_cols[c], \n",
    "        effect_times=test_interaction_time_cols[e], \n",
    "        pi=pred_cols[c], \n",
    "        clip=0.5, \n",
    "        drop_inverted=True, \n",
    "        stabilized=True)\n",
    "\n",
    "    return {\n",
    "        \"cause_id\": pair[0],\n",
    "        \"effect_id\": pair[1],\n",
    "        \"ATE\": ate_results[\"ATE\"],\n",
    "        \"STD\": ate_results[\"STD\"],\n",
    "        \"ABLT\": ablt_results[\"ATE\"],\n",
    "        \"STD_ABLT\": ablt_results[\"STD\"],\n",
    "        \"cosine_similarity\": cosimilarity(*pair),\n",
    "        \"correlation\": correlation(*pair),\n",
    "        \"diff_of_conditionals\": diff_of_conditionals(*pair),\n",
    "        \"jacard_index\": jacard_index(*pair),\n",
    "        \"sasrec_score\": sasrec_scores[pair],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a2d550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7d6921e8c34abea8c19068199326e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "for pair in tqdm(chosen_ids):\n",
    "    results = process_pair(pair)\n",
    "    all_results.append(results)\n",
    "\n",
    "raw_results = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b64cb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(\n",
    "    left=oracle,\n",
    "    right=raw_results,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "merged.to_csv(base_artifacts / 'Datasets' / 'Sequels' / 'sequels_evaluated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
