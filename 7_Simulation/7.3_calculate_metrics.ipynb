{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c132ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().resolve().parents[0] / '2_Propensities'))\n",
    "\n",
    "import MF_class as MF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2252314",
   "metadata": {},
   "source": [
    "# 1 Loading Dataset and Propensities Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318d80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_artifacts = Path.cwd().resolve().parents[1] / 'CausalI2I_artifacts'\n",
    "data_path = base_artifacts / 'Datasets' / 'Simulation'\n",
    "\n",
    "train = pd.read_csv(data_path / 'train.csv')\n",
    "test = pd.read_csv(data_path / 'test.csv')\n",
    "gt = pd.read_csv(data_path / 'ground_truth_processed.csv')\n",
    "\n",
    "n_users = len(train['user_id'].unique())\n",
    "n_items = len(train['item_id'].unique())\n",
    "\n",
    "full_data = pd.concat([train, test], ignore_index=True)\n",
    "oracle_dict = gt.set_index(['cause_id', 'effect_id']).to_dict()['causal_effect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d0b171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model summary:\n",
      "Model:                      MatrixFactorizationTorch\n",
      "Number of users:            6040\n",
      "Number of items:            3952\n",
      "Number of factors:          20\n",
      "Learning rate:              0.002\n",
      "Weight decay:               1e-07\n",
      "Positive weight:            1\n",
      "Batch size:                 32768\n",
      "Number of epochs:           50\n",
      "Device:                     cuda:0\n",
      "Use AMP:                    True\n",
      "Timestamp:                  2026-01-28 18:28:10\n"
     ]
    }
   ],
   "source": [
    "model = MF.MatrixFactorizationTorch(n_users, n_items, n_factors=20)\n",
    "model.load(path=base_artifacts / 'Propensity_Models' / 'MF20_simulation.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fcbc49",
   "metadata": {},
   "source": [
    "# 2 Defining Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8891d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_real = full_data.pivot(index='user_id', columns='item_id', values='watched').fillna(0)\n",
    "itemid_to_colidx_pivot_real = {item_id: col_idx for col_idx, item_id in enumerate(pivot_real.columns)}\n",
    "pivot_real_np = pivot_real.values\n",
    "\n",
    "Q_normalized = (model.Q / torch.norm(model.Q, dim=1, keepdim=True)).cpu().detach().numpy()\n",
    "\n",
    "def cosimilarity(idx1, idx2):\n",
    "    \"\"\"Calculate cosine similarity between two items.\"\"\"\n",
    "    return np.dot(Q_normalized[idx1], Q_normalized[idx2])\n",
    "\n",
    "def correlation(idx1, idx2):\n",
    "    \"\"\"Calculate correlation between two items.\"\"\"\n",
    "    colidx1 = itemid_to_colidx_pivot_real[idx1]\n",
    "    colidx2 = itemid_to_colidx_pivot_real[idx2]\n",
    "    T = pivot_real_np[:, colidx1]\n",
    "    Y = pivot_real_np[:, colidx2]\n",
    "    if T.std() == 0 or Y.std() == 0:\n",
    "        return 0\n",
    "    return np.corrcoef(T, Y)[0, 1]\n",
    "\n",
    "def diff_of_conditionals(idx1, idx2):\n",
    "    \"\"\"Calculate difference of conditionals P(Y|T) - P(Y|~T) between two items.\"\"\"\n",
    "    colidx1 = itemid_to_colidx_pivot_real[idx1]\n",
    "    colidx2 = itemid_to_colidx_pivot_real[idx2]\n",
    "    T = pivot_real_np[:, colidx1]\n",
    "    Y = pivot_real_np[:, colidx2]\n",
    "    p_T = np.clip(np.mean(T), 1e-6, 1-1e-6)\n",
    "    p_Y = np.mean(Y)\n",
    "    p_TY = np.mean(T * Y)\n",
    "    return p_TY / p_T - (p_Y - p_TY) / (1 - p_T)\n",
    "\n",
    "def jacard_index(idx1, idx2):\n",
    "    \"\"\"Calculate Jaccard index between two items.\"\"\"\n",
    "    colidx1 = itemid_to_colidx_pivot_real[idx1]\n",
    "    colidx2 = itemid_to_colidx_pivot_real[idx2]\n",
    "    T = pivot_real_np[:, colidx1]\n",
    "    Y = pivot_real_np[:, colidx2]\n",
    "    intersection = np.sum((T > 0) & (Y > 0))\n",
    "    union = np.sum((T > 0) | (Y > 0))\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06268f3",
   "metadata": {},
   "source": [
    "# 3 Defining ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3376f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = model.predict_prob(\n",
    "        torch.tensor(test['user_id'].values, dtype=torch.long),\n",
    "        torch.tensor(test['item_id'].values, dtype=torch.long)\n",
    "    )\n",
    "test_copy = test.copy()\n",
    "if test_copy['timestamp'].dtype == 'O':\n",
    "    test_copy['timestamp'] = pd.to_datetime(test_copy['timestamp'], errors='coerce').astype(np.int64) // 10**9\n",
    "    test_copy['timestamp'] = test_copy['timestamp'].apply(lambda x: x if x > 0 else np.inf)\n",
    "\n",
    "pivot_test_timestamp = test_copy.pivot(index='user_id', columns='item_id', values='timestamp').fillna(np.inf)\n",
    "pivot_test_timestamp_np = pivot_test_timestamp.values\n",
    "itemid_to_colidx = {id: i for i, id in enumerate(pivot_test_timestamp.columns)}\n",
    "\n",
    "test_copy['probability'] = test_probs.cpu().detach().numpy()\n",
    "pivot_test_pred = test_copy.pivot(index='user_id', columns='item_id', values='probability')\n",
    "pivot_test_pred_np = pivot_test_pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fadcd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interaction_time_cols  = {\n",
    "    item: pivot_test_timestamp_np[:, colidx]\n",
    "    for item, colidx in itemid_to_colidx.items()\n",
    "}\n",
    "\n",
    "pred_cols = {\n",
    "    item: pivot_test_pred_np[:, colidx]\n",
    "    for item, colidx in itemid_to_colidx.items()\n",
    "}\n",
    "\n",
    "all_interaction_cols = {\n",
    "    item: pivot_real_np[:, colidx]\n",
    "    for item, colidx in itemid_to_colidx_pivot_real.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0a4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ATE(cause_times, effect_times, pi, clip=0, drop_inverted=True, stabilized=True):\n",
    "    \"\"\"\n",
    "    If stabilized=True  -> Hájek ratio IPW: E[Y(1)] ≈ mean(N1)/mean(D1), E[Y(0)] ≈ mean(N0)/mean(D0)\n",
    "    If stabilized=False -> Horvitz–Thompson IPW:   E[Y(1)] ≈ mean(N1),    E[Y(0)] ≈ mean(N0)\n",
    "    Returns (ATE, STD) unless return_STD=False.\n",
    "    \"\"\"\n",
    "\n",
    "    if drop_inverted:\n",
    "        users_to_keep = np.where((cause_times <= effect_times) | (cause_times == np.inf))[0]\n",
    "\n",
    "        cause_time_filtered = cause_times[users_to_keep]\n",
    "        effect_time_filtered = effect_times[users_to_keep]\n",
    "\n",
    "        T = cause_time_filtered < np.inf\n",
    "        Y = effect_time_filtered < np.inf\n",
    "        pi = pi[users_to_keep]\n",
    "\n",
    "    else:\n",
    "        T  = cause_times < np.inf\n",
    "        Y  = effect_times < np.inf\n",
    "    \n",
    "    n  = len(T)\n",
    "\n",
    "    pi = np.clip(pi, clip, 1 - clip)\n",
    "\n",
    "    # IPW pieces\n",
    "    D_1 = T / pi                # B\n",
    "    D_0 = (1 - T) / (1 - pi)    # D\n",
    "    N_1 = Y * D_1               # A\n",
    "    N_0 = Y * D_0               # C\n",
    "\n",
    "    mN_1, mN_0 = N_1.mean(), N_0.mean()\n",
    "    \n",
    "    # Point estimate\n",
    "    if stabilized:\n",
    "        # Hájek (ratio) form\n",
    "        mD_1, mD_0 = D_1.mean(), D_0.mean()\n",
    "        EY_1 = mN_1 / mD_1 if mD_1 != 0 else 0.0\n",
    "        EY_0 = mN_0 / mD_0 if mD_0 != 0 else 0.0\n",
    "    else:\n",
    "        # Horvitz–Thompson (mean) form\n",
    "        EY_1 = mN_1\n",
    "        EY_0 = mN_0\n",
    "\n",
    "    ATE = EY_1 - EY_0\n",
    "\n",
    "    # ---- Variance via explicit covariance matrix ----\n",
    "    if stabilized:\n",
    "        Z = np.column_stack([N_1, D_1, N_0, D_0])\n",
    "        S = np.cov(Z, rowvar=False, ddof=1)     # 4x4 sample covariance\n",
    "        g = np.array([\n",
    "            1.0 / mD_1 if mD_1 != 0 else 0.0,\n",
    "            -mN_1 / (mD_1 ** 2) if mD_1 != 0 else 0.0,\n",
    "            -1.0 / mD_0 if mD_0 != 0 else 0.0,\n",
    "            mN_0 / (mD_0 ** 2) if mD_0 != 0 else 0.0\n",
    "        ])\n",
    "    else:\n",
    "        Z = np.column_stack([N_1, N_0])\n",
    "        S = np.cov(Z, rowvar=False, ddof=1)     # 2x2 covariance\n",
    "        g = np.array([1.0, -1.0])\n",
    "    \n",
    "    var_hat = (g @ S @ g) / n\n",
    "    STD = float(np.sqrt(max(var_hat, 0.0)))     # numerical safety\n",
    "    return {\n",
    "        \"ATE\": ATE,\n",
    "        \"STD\": STD\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ff0d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total item pairs in oracle: 613\n",
      "Total item pairs not in oracle: 623,487\n",
      "Total item pairs to evaluate: 10,613\n"
     ]
    }
   ],
   "source": [
    "test_items = test['item_id'].unique()\n",
    "test_pairs = list(product(test_items, test_items))\n",
    "\n",
    "good_pairs = []\n",
    "for pair in test_pairs:\n",
    "    if pair in oracle_dict:\n",
    "        good_pairs.append(pair)\n",
    "print(f\"Total item pairs in oracle: {len(good_pairs)}\")\n",
    "\n",
    "bad_pairs = list(set(test_pairs) - set(good_pairs))\n",
    "print(f\"Total item pairs not in oracle: {len(bad_pairs):,}\")\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "chosen_null_pairs = rng.choice(bad_pairs, size=10000, replace=False)\n",
    "chosen_null_pairs = [tuple(pair) for pair in chosen_null_pairs]\n",
    "\n",
    "all_pairs = good_pairs + chosen_null_pairs\n",
    "print(f\"Total item pairs to evaluate: {len(all_pairs):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4470e72",
   "metadata": {},
   "source": [
    "# 4 Generate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pair(pair):\n",
    "\n",
    "    c = pair[0]\n",
    "    e = pair[1]\n",
    "\n",
    "    ate_result = get_ATE(\n",
    "        cause_times=test_interaction_time_cols[c], \n",
    "        effect_times=test_interaction_time_cols[e], \n",
    "        pi=pred_cols[c], \n",
    "        clip=0.01, \n",
    "        drop_inverted=True, \n",
    "        stabilized=True)\n",
    "    \n",
    "    ablt_result = get_ATE(\n",
    "        cause_times=test_interaction_time_cols[c], \n",
    "        effect_times=test_interaction_time_cols[e], \n",
    "        pi=pred_cols[c], \n",
    "        clip=0.5, \n",
    "        drop_inverted=True, \n",
    "        stabilized=True)\n",
    "    \n",
    "    if pair in oracle_dict:\n",
    "        true_ate = oracle_dict[pair]\n",
    "    else:\n",
    "        true_ate = 0.0\n",
    "\n",
    "    return {\n",
    "        \"cause_id\": pair[0],\n",
    "        \"effect_id\": pair[1],\n",
    "        \"ATE\": ate_result[\"ATE\"],\n",
    "        \"STD\": ate_result[\"STD\"],\n",
    "        \"ABLT\": ablt_result[\"ATE\"],\n",
    "        \"STD_ABLT\": ablt_result[\"STD\"],\n",
    "        \"cosine_similarity\": cosimilarity(*pair),\n",
    "        \"correlation\": correlation(*pair),\n",
    "        \"diff_of_conditionals\": diff_of_conditionals(*pair),\n",
    "        \"jacard_index\": jacard_index(*pair),\n",
    "        \"causal_effect\": true_ate\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71a2d550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0cb5b171c34777b9d238f3ee05309e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "for pair in tqdm(all_pairs):\n",
    "    results = process_pair(pair)\n",
    "    all_results.append(results)\n",
    "\n",
    "raw_results = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b64cb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results.to_csv(base_artifacts / 'Datasets' / 'Simulation' / 'simulation_evaluated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
