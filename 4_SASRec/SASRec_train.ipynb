{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f277c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import SASRec_class as sasrec\n",
    "\n",
    "np.random.seed(42)\n",
    "if np.random.choice(np.arange(1000)) != 102:\n",
    "    raise ValueError(\"Random seed is not set correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ead12",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22120fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'steam'\n",
    "base_artifacts = Path.cwd().resolve().parents[1] / 'CausalI2I_artifacts'\n",
    "data_sasrec = pd.read_csv(\n",
    "    base_artifacts / 'Datasets' / 'Processed' / DATASET / 'data_sasrec.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f6ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'ml-1m': {\n",
    "        'L': 200, \n",
    "        'dropout': 0.2, \n",
    "        'batch_size': 128,\n",
    "        'num_epochs': 10},\n",
    "    'steam': {\n",
    "        'L': 50, \n",
    "        'dropout': 0.5, \n",
    "        'batch_size': 2**11,\n",
    "        'num_epochs': 20},\n",
    "    'goodreads': {\n",
    "        'L': 50, \n",
    "        'dropout': 0.5, \n",
    "        'batch_size': 2**11,\n",
    "        'num_epochs': 20}\n",
    "}\n",
    "\n",
    "L = parameters_dict[DATASET]['L']\n",
    "dropout = parameters_dict[DATASET]['dropout']\n",
    "batch_size = parameters_dict[DATASET]['batch_size']\n",
    "num_epochs = parameters_dict[DATASET]['num_epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4dc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = data_sasrec['user_id'].unique()\n",
    "n_users = len(unique_users)\n",
    "\n",
    "train_users = np.random.choice(\n",
    "    unique_users, \n",
    "    size=int(0.8 * n_users), \n",
    "    replace=False)\n",
    "test_users = np.setdiff1d(unique_users, train_users)\n",
    "\n",
    "num_items = data_sasrec['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a238ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(162.60485413677665)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_dict = data_sasrec.groupby('user_id')['item_id'].apply(list).to_dict()\n",
    "lens = [len(users_dict[user]) for user in users_dict]\n",
    "np.mean(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_idx = num_items\n",
    "\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "for user_id in users_dict:\n",
    "    users_dict[user_id] = [padding_idx] * (L - 2) + users_dict[user_id]\n",
    "    i = 0\n",
    "    while i + L <= len(users_dict[user_id]):\n",
    "        if user_id in train_users:\n",
    "            train_dataset.append(users_dict[user_id][i:i+L])\n",
    "        else:\n",
    "            test_dataset.append(users_dict[user_id][i:i+L])\n",
    "        i += 1\n",
    "train_dataset = np.array(train_dataset)\n",
    "test_dataset = np.array(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54223ab9",
   "metadata": {},
   "source": [
    "# 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a05c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gouni/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | T-Loss | V-Loss | Pctl  | HR10  | NDCG  | CosÎ¸  | Elapsed Time\n",
      "======|========|========|=======|=======|=======|=======|=============\n",
      "    1 |  1.062 |  0.889 | 0.856 | 0.564 | 0.415 | None  |     00:24.3\n",
      "    2 |  0.853 |  0.796 | 0.887 | 0.642 | 0.455 | 0.515 |     00:48.3\n",
      "    3 |  0.779 |  0.741 | 0.903 | 0.689 | 0.482 | 0.555 |     01:11.9\n",
      "    4 |  0.722 |  0.699 | 0.915 | 0.727 | 0.509 | 0.554 |     01:35.7\n",
      "    5 |  0.682 |  0.677 | 0.921 | 0.748 | 0.525 | 0.578 |     01:59.5\n",
      "    6 |  0.661 |  0.668 | 0.924 | 0.758 | 0.533 | 0.609 |     02:23.5\n",
      "    7 |  0.647 |  0.661 | 0.926 | 0.765 | 0.539 | 0.613 |     02:47.4\n",
      "    8 |  0.635 |  0.655 | 0.928 | 0.770 | 0.544 | 0.575 |     03:11.5\n",
      "    9 |  0.624 |  0.648 | 0.930 | 0.776 | 0.551 | 0.548 |     03:35.7\n",
      "   10 |  0.612 |  0.643 | 0.931 | 0.781 | 0.555 | 0.558 |     03:59.7\n",
      "   11 |  0.604 |  0.639 | 0.932 | 0.785 | 0.558 | 0.523 |     04:23.7\n",
      "   12 |  0.596 |  0.636 | 0.933 | 0.788 | 0.561 | 0.498 |     04:47.8\n",
      "   13 |  0.589 |  0.633 | 0.934 | 0.790 | 0.563 | 0.473 |     05:11.7\n",
      "   14 |  0.584 |  0.634 | 0.934 | 0.791 | 0.564 | 0.432 |     05:35.6\n",
      "   15 |  0.580 |  0.633 | 0.934 | 0.793 | 0.566 | 0.395 |     05:59.7\n",
      "   16 |  0.576 |  0.633 | 0.935 | 0.793 | 0.566 | 0.370 |     06:23.8\n",
      "   17 |  0.572 |  0.633 | 0.935 | 0.793 | 0.567 | 0.356 |     06:47.9\n",
      "   18 |  0.568 |  0.633 | 0.935 | 0.794 | 0.568 | 0.338 |     07:11.9\n",
      "   19 |  0.565 |  0.634 | 0.935 | 0.794 | 0.568 | 0.314 |     07:35.8\n",
      "   20 |  0.562 |  0.634 | 0.935 | 0.795 | 0.569 | 0.293 |     07:59.7\n"
     ]
    }
   ],
   "source": [
    "model = sasrec.SASRecTorch(\n",
    "    num_items=num_items,\n",
    "    max_seq_len=L,\n",
    "    d_model=50,\n",
    "    n_heads=1,\n",
    "    n_layers=2,\n",
    "    dropout=dropout,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "model.fit(\n",
    "    train_dataset=train_dataset,\n",
    "    valid_dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0, \n",
    "    num_epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc183d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = base_artifacts / 'SASRec_Models'\n",
    "model.save(path=folder_path / f'sasrec_{DATASET}.pt')\n",
    "\n",
    "init_dict = {\n",
    "    \"num_items\": num_items,\n",
    "    \"max_seq_len\": L,\n",
    "    \"d_model\": model.d_model,\n",
    "    \"n_heads\": model.n_heads,\n",
    "    \"n_layers\": model.n_layers,\n",
    "    \"dropout\": model.dropout,\n",
    "    \"device\": model.device\n",
    "}\n",
    "\n",
    "with open(folder_path / f'sasrec_{DATASET}_init_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(init_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed79be",
   "metadata": {},
   "source": [
    "# 3. Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3207d480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gouni/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /home/gouni/CausalI2I_artifacts/SASRec_Models/sasrec_steam.pt.\n",
      "num_items:     12434\n",
      "max_seq_len:   50\n",
      "device:        cuda\n",
      "batch_size:    2048\n",
      "lr:            0.001\n",
      "weight_decay:  0.0\n",
      "num_epochs:    20\n",
      "saved_at:      2026-01-03 12:00:39\n",
      "note:          None\n"
     ]
    }
   ],
   "source": [
    "folder_path = base_artifacts / 'SASRec_Models'\n",
    "with open(folder_path / f'sasrec_{DATASET}_init_dict.pkl', 'rb') as f:\n",
    "    init_dict_loaded = pickle.load(f)\n",
    "\n",
    "loaded_model = sasrec.SASRecTorch(**init_dict_loaded)\n",
    "loaded_model.load(folder_path / f'sasrec_{DATASET}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
